{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import itertools\n",
    "from spleeter.separator import Separator\n",
    "from spleeter.audio import STFTBackend, Codec\n",
    "from spleeter.audio.adapter import AudioAdapter\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import IPython.display as ipd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_dict = {\n",
    "    'Hip-Hop': 0,\n",
    "    'Pop': 1,\n",
    "    'Rock': 2,\n",
    "    'Folk': 3,\n",
    "    'Experimental': 4,\n",
    "    'Jazz': 5,\n",
    "    'Electronic': 6,\n",
    "    'International': 7,\n",
    "    'Soul-RnB': 8,\n",
    "    'Blues': 9,\n",
    "    'Spoken': 10,\n",
    "    'Country': 11,\n",
    "    'Classical': 12,\n",
    "    'Old-Time / Historic': 13,\n",
    "    'Instrumental': 14,\n",
    "    'Easy Listening': 15\n",
    "}\n",
    "\n",
    "channel_labels = [\"vocals\", \"drums\", \"bass\", \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        audio, sr = librosa.load(file, mono=False, sr=44100)\n",
    "\n",
    "    # If loaded audio is only mono duplicate channel\n",
    "    if audio.shape[0] != 2:\n",
    "        audio = np.array([\n",
    "            audio,\n",
    "            audio\n",
    "        ])\n",
    "\n",
    "    if audio.shape[1] < 30*44100:\n",
    "        audio = np.array([\n",
    "            np.pad(audio[0], (0, 30*44100 - audio.shape[1]), mode='constant', constant_values=0),\n",
    "            np.pad(audio[1], (0, 30*44100 - audio.shape[1]), mode='constant', constant_values=0)\n",
    "        ])\n",
    "\n",
    "    return audio\n",
    "\n",
    "\n",
    "def slice_snippets(audio):\n",
    "    # Slice audio in 10 second parts\n",
    "    slice_length = 10 # seconds\n",
    "    surplus = audio.shape[1] % (44100 * slice_length)\n",
    "    number_of_snippets = audio.shape[1] // (44100 * slice_length)\n",
    "    audio_snippets = np.array([\n",
    "        np.array_split(audio[0][surplus:], number_of_snippets),\n",
    "        np.array_split(audio[1][surplus:], number_of_snippets)\n",
    "    ])\n",
    "\n",
    "    # Prepare slices\n",
    "    prepared_snippets = []\n",
    "    for index in range(audio_snippets.shape[1]):\n",
    "        prepared_snippets.append(\n",
    "            np.array([\n",
    "                audio_snippets[0][index],\n",
    "                audio_snippets[1][index],\n",
    "            ])\n",
    "        )\n",
    "    \n",
    "    return prepared_snippets\n",
    "\n",
    "\n",
    "def compute_source_separation(prepared_snippets):\n",
    "    # Init Spleeter Separator\n",
    "    seperator = Separator(\"spleeter:4stems\", STFTBackend.TENSORFLOW, multiprocess=False)\n",
    "    # Compute \n",
    "    source_seperation_slices = []\n",
    "    for prepared_slice in prepared_snippets:\n",
    "        prepared_slice = prepared_slice.reshape(prepared_slice.shape[1],prepared_slice.shape[0])\n",
    "        source_seperation_slices.append(seperator.separate(prepared_slice, \"\"))\n",
    "    \n",
    "    return source_seperation_slices\n",
    "\n",
    "\n",
    "def to_mono(waveform):\n",
    "    if waveform.shape[0] != 2:\n",
    "        waveform = waveform.reshape( \n",
    "            (waveform.shape[1], waveform.shape[0])\n",
    "        )\n",
    "    \n",
    "    return librosa.to_mono(waveform)\n",
    "\n",
    "\n",
    "def compute_spectrogramms(source_seperation_slices):\n",
    "    spectrogram_slices = []\n",
    "    for source_seperation_slice in source_seperation_slices:\n",
    "        temp = {}\n",
    "        for key, prediction in source_seperation_slice.items():\n",
    "            temp[key] = librosa.power_to_db(\n",
    "                librosa.feature.melspectrogram(\n",
    "                    to_mono(prediction),\n",
    "                    sr=44100,\n",
    "                    n_fft=2048,\n",
    "                    hop_length=1024\n",
    "                ),\n",
    "                ref=np.max\n",
    "            )\n",
    "        spectrogram_slices.append(temp)\n",
    "    \n",
    "    x = []\n",
    "    for spectrogram_slice in spectrogram_slices:\n",
    "        x.append(np.array(list(spectrogram_slice.values())))\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_tensorflow_model(model_path):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        return tf.keras.models.load_model(model_path, custom_objects={'tf': tf})\n",
    "\n",
    "\n",
    "def explain_snippets(x_test, model):\n",
    "    # Create Channel permutation to test and remove empty and full permutation\n",
    "    l = [0,1]\n",
    "    z_ = list(itertools.product(l, repeat=4))\n",
    "    z_.remove((0,0,0,0))\n",
    "    z_.remove((1,1,1,1))\n",
    "\n",
    "    snippet_data = []\n",
    "    for index, x in enumerate(x_test):\n",
    "        print(f'Snippet number {index + 1}')\n",
    "        \n",
    "        Z_y = []\n",
    "        \n",
    "        # Get prediction for full input\n",
    "        full_prediction = model.predict(np.array([x]))\n",
    "        full_predictet_confidence = np.amax(np.squeeze(full_prediction))\n",
    "        full_predictet_label = list(\n",
    "            genres_dict.keys())[\n",
    "            list(genres_dict\n",
    "                 .values())\n",
    "            .index(\n",
    "                np.argmax(\n",
    "                    np.squeeze(full_prediction)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        print(f'Predicted {full_predictet_label} with confidence of {full_predictet_confidence}')\n",
    "        \n",
    "        # Create Sample and get label for prediction\n",
    "        for permutation in list(z_):\n",
    "            z = np.copy(x)\n",
    "            for index, value in enumerate(permutation):\n",
    "                if value == 0:\n",
    "                    z[index] = np.full((z[index].shape[0], z[index].shape[1]), -80)\n",
    "            z_prediction = model.predict(np.array([z]))\n",
    "            \n",
    "            # Get most confident value\n",
    "            predictet_label = np.argmax(np.squeeze(z_prediction))\n",
    "            Z_y.append(np.squeeze(z_prediction)[genres_dict[full_predictet_label]])\n",
    "            print(f'Model predictet {list(genres_dict.keys())[list(genres_dict.values()).index(predictet_label)]} for permutation {permutation}; Target label with {np.squeeze(z_prediction)[genres_dict[full_predictet_label]]}')\n",
    "\n",
    "        # Train explainable model for \n",
    "        reg = LinearRegression()\n",
    "        reg.fit(z_, Z_y)\n",
    "\n",
    "        snippet_data.append({\n",
    "            \"weights\": reg.coef_,\n",
    "            \"label\": full_predictet_label,\n",
    "            \"confidence\": full_predictet_confidence\n",
    "        })\n",
    "\n",
    "    return snippet_data\n",
    "\n",
    "def evalate_explanations(snippet_explanations, source_separation_snippets):\n",
    "    total_snippets = len(snippet_explanations)\n",
    "    predictet_labels_count = {}\n",
    "    for explanations in snippet_explanations:\n",
    "        if explanations[\"label\"] in predictet_labels_count:\n",
    "            predictet_labels_count[explanations[\"label\"]] = predictet_labels_count[explanations[\"label\"]] + 1\n",
    "        else:\n",
    "            predictet_labels_count[explanations[\"label\"]] = 1\n",
    "    print('Predicted labels for the song')\n",
    "    for label, count in predictet_labels_count.items():\n",
    "        print(f'{label}: {count / total_snippets * 100} %')\n",
    "    \n",
    "    # Left and Right audio channel for reconstruction\n",
    "    l = []\n",
    "    r = []\n",
    "    for index, explanation in enumerate(snippet_explanations):\n",
    "        # Slect most importent feature by regression weight\n",
    "        most_important_feature = np.argmax(explanation['weights'])\n",
    "        # create explantion time line\n",
    "        print(f'{time.strftime(\"%M:%S\", time.gmtime((index * 10)))} - {time.strftime(\"%M:%S\", time.gmtime((index + 1)* 10))}: Predicted {explanation[\"label\"]} with confidence of {explanation[\"confidence\"]} by feature {channel_labels[most_important_feature]} with weight {explanation[\"weights\"][most_important_feature]}')\n",
    "        \n",
    "        # Prepare snippet for audio conversion\n",
    "        snippet = source_separation_snippets[index][channel_labels[most_important_feature]]\n",
    "        snippet = snippet.reshape((snippet.shape[1], snippet.shape[0]))\n",
    "        l.append(snippet[0])\n",
    "        r.append(snippet[1])\n",
    "        \n",
    "\n",
    "    # concat snippets for full audio explanation\n",
    "    l = np.concatenate(l, axis=0)\n",
    "    r = np.concatenate(r, axis=0)\n",
    "\n",
    "    ipd.display(\n",
    "        ipd.Audio(\n",
    "            np.array([l,r]), \n",
    "            rate=44100\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess_instance_snippet(file_path, model_path):\n",
    "    audio = load_file(file_path)\n",
    "    snippets = slice_snippets(audio)\n",
    "    source_separation_snippets = compute_source_separation(snippets)\n",
    "    spectrogram_snippets = compute_spectrogramms(source_separation_snippets)\n",
    "    model = load_tensorflow_model(model_path)\n",
    "    snippet_explanations = explain_snippets(spectrogram_snippets, model)\n",
    "    evalate_explanations(snippet_explanations, source_separation_snippets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_path = '/data'\n",
    "model_path = os.path.join(data_base_path,'logs','DropOriginalMultiChannelParallelCRNN','fma_medium_SpleeterGPUPreprocessor_spleeter:4stems_keepOriginal_LibrosaCPUSTFT','10-03-2022-14-25-21','trained_model')\n",
    "\n",
    "darkness_path = os.path.join(data_base_path,'Deathweight','Deathweight-Darkness.mp3')\n",
    "\n",
    "preprocess_instance_snippet(darkness_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_path = '/data'\n",
    "model_path = os.path.join(data_base_path, 'logs','DropOriginalMultiChannelParallelCRNN','fma_medium_SpleeterGPUPreprocessor_spleeter:4stems_keepOriginal_LibrosaCPUSTFT','10-03-2022-14-25-21','trained_model')\n",
    "\n",
    "volition_path = os.path.join(data_base_path,'Deathweight', 'Deathweight-Volition.mp3')\n",
    "\n",
    "preprocess_instance_snippet(volition_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
