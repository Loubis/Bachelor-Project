{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge\n",
    "import scipy.spatial.distance as dist\n",
    "import time\n",
    "\n",
    "import librosa\n",
    "from spleeter.separator import Separator\n",
    "from spleeter.audio import STFTBackend\n",
    "from spleeter.audio.adapter import AudioAdapter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "data_base_path = '/data'\n",
    "model_path = os.path.join(data_base_path, 'logs','DropOriginalMultiChannelParallelCRNN','fma_medium_SpleeterGPUPreprocessor_spleeter:4stems_keepOriginal_LibrosaCPUSTFT','12-03-2022-14-05-56','trained_model')\n",
    "metadata_file = os.path.join(data_base_path, 'fma_metadata', 'tracks.csv')\n",
    "audio_data_path = os.path.join(data_base_path, 'fma_medium')\n",
    "# Init Spleeter Separator\n",
    "seperator = Separator(\"spleeter:4stems\", STFTBackend.TENSORFLOW, multiprocess=False)\n",
    "\n",
    "audio_loader = AudioAdapter.default()\n",
    "sample_rate = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get samples\n",
    "# List of songs empty or shorter songs\n",
    "# Source: https://github.com/mdeff/fma/wiki#excerpts-shorter-than-30s-and-erroneous-audio-length-metadata (last visit 07.02.2022)\n",
    "excluded_shorter_tracks = [\n",
    "    \"1486\",\n",
    "    \"5574\",\n",
    "    \"65753\",\n",
    "    \"80391\",\n",
    "    \"98558\",\n",
    "    \"98559\",\n",
    "    \"98560\",\n",
    "    \"98565\",\n",
    "    \"98566\",\n",
    "    \"98567\",\n",
    "    \"98568\",\n",
    "    \"98569\",\n",
    "    \"98571\",\n",
    "    \"99134\",\n",
    "    \"105247\",\n",
    "    \"108924\",\n",
    "    \"108925\",\n",
    "    \"126981\",\n",
    "    \"127336\",\n",
    "    \"133297\",\n",
    "    \"143992\",\n",
    "]\n",
    "# Load CSV and take medium subset and exclude faulty tracks\n",
    "df = pd.read_csv(metadata_file, index_col=0, header=[0, 1])\n",
    "df = df[df[(\"set\", \"subset\")].isin([\"small\",\"medium\"])]\n",
    "df = df[~df.index.isin(excluded_shorter_tracks)]\n",
    "\n",
    "# Generate genre dictionary\n",
    "genres_dict = {}\n",
    "genres = df[(\"track\", \"genre_top\")].dropna().unique()\n",
    "for label in genres:\n",
    "    genres_dict.update({ label: len(genres_dict) })\n",
    "print(genres_dict)\n",
    "    \n",
    "# Filter Test subset\n",
    "df = df[df[(\"set\", \"split\")] == \"test\"]\n",
    "df = df[[(\"track\", \"genre_top\")]]\n",
    "\n",
    "df_hip_hop = df[df[(\"track\", \"genre_top\")] == 'Hip-Hop']\n",
    "df_rock = df[df[(\"track\", \"genre_top\")] == 'Rock']\n",
    "df_pop = df[df[(\"track\", \"genre_top\")] == 'Pop']\n",
    "df_jazz = df[df[(\"track\", \"genre_top\")] == 'Jazz']\n",
    "df_electronic = df[df[(\"track\", \"genre_top\")] == 'Electronic']\n",
    "\n",
    "#print(df_hip_hop)\n",
    "#print(df_rock)\n",
    "#print(df_pop)\n",
    "#print(df_jazz)\n",
    "#print(df_electronic)\n",
    "\n",
    "example_hip_hop_id = 14360\n",
    "example_rock_id = 152671\n",
    "example_pop_id = 12387\n",
    "# example_jazz_id = 67045 gutes example für mögliche vertauschung mit classic\n",
    "# example_jazz_id = 47504 beispiel für jazz mit ende als rock durch verzerrte gitarre und pushing beat\n",
    "example_jazz_id = 12374\n",
    "example_electronic_id = 151534\n",
    "\n",
    "example_hip_hop_path = os.path.join(audio_data_path, \"{:06d}\".format(example_hip_hop_id)[:3], \"{:06d}\".format(example_hip_hop_id) + \".mp3\")\n",
    "example_rock_path = os.path.join(audio_data_path, \"{:06d}\".format(example_rock_id)[:3], \"{:06d}\".format(example_rock_id) + \".mp3\")\n",
    "example_pop_path = os.path.join(audio_data_path, \"{:06d}\".format(example_pop_id)[:3], \"{:06d}\".format(example_pop_id) + \".mp3\")\n",
    "example_jazz_path = os.path.join(audio_data_path, \"{:06d}\".format(example_jazz_id)[:3], \"{:06d}\".format(example_jazz_id) + \".mp3\")\n",
    "example_electronic_path = os.path.join(audio_data_path, \"{:06d}\".format(example_electronic_id)[:3], \"{:06d}\".format(example_electronic_id) + \".mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    hiphop_audio, sr = librosa.load(example_hip_hop_path, mono=False, sr=44100, duration=30.0)\n",
    "\n",
    "source_separation = seperator.separate(hiphop_audio.reshape(hiphop_audio.shape[1],hiphop_audio.shape[0]), \"\")\n",
    "\n",
    "print(\"Full mix\")\n",
    "ipd.display(ipd.Audio(hiphop_audio, rate=sr))\n",
    "\n",
    "for key, value in source_separation.items():\n",
    "    print(key)\n",
    "    ipd.display(ipd.Audio(value.reshape(hiphop_audio.shape), rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    rock_audio, sr = librosa.load(example_rock_path, mono=False, sr=44100, duration=30.0)\n",
    "\n",
    "source_separation = seperator.separate(rock_audio.reshape(rock_audio.shape[1],rock_audio.shape[0]), \"\")\n",
    "\n",
    "print(\"Full mix\")\n",
    "ipd.display(ipd.Audio(rock_audio, rate=sr))\n",
    "\n",
    "for key, value in source_separation.items():\n",
    "    print(key)\n",
    "    ipd.display(ipd.Audio(value.reshape(rock_audio.shape), rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    electronic_audio, sr = librosa.load(example_electronic_path, mono=False, sr=44100, duration=30.0)\n",
    "\n",
    "source_separation = seperator.separate(electronic_audio.reshape(electronic_audio.shape[1],electronic_audio.shape[0]), \"\")\n",
    "\n",
    "print(\"Full mix\")\n",
    "ipd.display(ipd.Audio(electronic_audio, rate=sr))\n",
    "\n",
    "for key, value in source_separation.items():\n",
    "    print(key)\n",
    "    ipd.display(ipd.Audio(value.reshape(electronic_audio.shape), rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    pop_audio, sr = librosa.load(example_pop_path, mono=False, sr=44100, duration=30.0)\n",
    "ipd.Audio(pop_audio, rate=sr)\n",
    "\n",
    "source_separation = seperator.separate(pop_audio.reshape(pop_audio.shape[1],pop_audio.shape[0]), \"\")\n",
    "\n",
    "print(\"Full mix\")\n",
    "ipd.display(ipd.Audio(pop_audio, rate=sr))\n",
    "\n",
    "for key, value in source_separation.items():\n",
    "    print(key)\n",
    "    ipd.display(ipd.Audio(value.reshape(pop_audio.shape), rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    jazz_audio, sr = librosa.load(example_jazz_path, mono=False, sr=44100, duration=30.0)\n",
    "ipd.Audio(jazz_audio, rate=sr)\n",
    "\n",
    "source_separation = seperator.separate(jazz_audio.reshape(jazz_audio.shape[1],jazz_audio.shape[0]), \"\")\n",
    "\n",
    "print(\"Full mix\")\n",
    "ipd.display(ipd.Audio(jazz_audio, rate=sr))\n",
    "\n",
    "for key, value in source_separation.items():\n",
    "    print(key)\n",
    "    ipd.display(ipd.Audio(value.reshape(jazz_audio.shape), rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deathweight example\n",
    "# Darkness\n",
    "deathweigth_path = os.path.join('/data','Deathweight', 'Deathweight-Darkness.mp3')\n",
    "# Volition\n",
    "#deathweigth_path = os.path.join('/data','Deathweight', 'Deathweight-Volition.mp3')\n",
    "\n",
    "#deathweigth_path = os.path.join('/data','Deathweight', 'Megadeth-Tornado_Of_Souls.mp3')\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    deathweigth_audio, sr = librosa.load(deathweigth_path, mono=False, sr=44100, duration=30.0)\n",
    "\n",
    "source_separation = seperator.separate(deathweigth_audio.reshape(deathweigth_audio.shape[1],deathweigth_audio.shape[0]), \"\")\n",
    "\n",
    "print(\"Full mix\")\n",
    "ipd.display(ipd.Audio(deathweigth_audio, rate=sr))\n",
    "\n",
    "for key, value in source_separation.items():\n",
    "    print(key)\n",
    "    ipd.display(ipd.Audio(value.reshape(deathweigth_audio.shape), rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = example_hip_hop_path\n",
    "label = 'Hip-Hop'\n",
    "#file = example_rock_path\n",
    "#label = 'Rock'\n",
    "#file = example_pop_path\n",
    "#label = 'Pop'\n",
    "#file = example_jazz_path\n",
    "#label = 'Jazz'\n",
    "#file = example_electronic_path\n",
    "#label = 'Electronic'\n",
    "\n",
    "#file = deathweigth_path\n",
    "#label = 'Rock'\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    audio, sr = librosa.load(file, mono=False, sr=44100, duration=30.0)\n",
    "\n",
    "# If loaded audio is only mono duplicate channel\n",
    "if audio.shape[0] != 2:\n",
    "    audio = np.array([\n",
    "        audio,\n",
    "        audio\n",
    "    ])\n",
    "\n",
    "if audio.shape[1] < 30*44100:\n",
    "    audio = np.array([\n",
    "        np.pad(audio[0], (0, 30*44100 - audio.shape[1]), mode='constant', constant_values=0),\n",
    "        np.pad(audio[1], (0, 30*44100 - audio.shape[1]), mode='constant', constant_values=0)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Slice audio in 10 second parts\n",
    "slice_length = 10 # seconds\n",
    "surplus = audio.shape[1] % (44100 * slice_length)\n",
    "number_of_slices = audio.shape[1] // (44100 * slice_length)\n",
    "audio_slices = np.array([\n",
    "    np.array_split(audio[0][surplus:], number_of_slices),\n",
    "    np.array_split(audio[1][surplus:], number_of_slices)\n",
    "])\n",
    "\n",
    "# Prepare slices\n",
    "prepared_slices = []\n",
    "for index in range(audio_slices.shape[1]):\n",
    "    prepared_slices.append(\n",
    "        np.array([\n",
    "            audio_slices[0][index],\n",
    "            audio_slices[1][index],\n",
    "        ])\n",
    "    )\n",
    "\n",
    "\n",
    "# Compute source separation\n",
    "source_seperation_slices = []\n",
    "for prepared_slice in prepared_slices:\n",
    "    prepared_slice = prepared_slice.reshape(prepared_slice.shape[1],prepared_slice.shape[0])\n",
    "    source_seperation_slices.append(seperator.separate(prepared_slice, \"\"))\n",
    "\n",
    "# helper function\n",
    "def to_mono(waveform):\n",
    "    if waveform.shape[0] != 2:\n",
    "        waveform = waveform.reshape( \n",
    "            (waveform.shape[1], waveform.shape[0])\n",
    "        )\n",
    "    return librosa.to_mono(waveform)\n",
    "\n",
    "# Compute spectrograms\n",
    "spectrogram_slices = []\n",
    "for source_seperation_slice in source_seperation_slices:\n",
    "    temp = {}\n",
    "    for key, prediction in source_seperation_slice.items():\n",
    "        temp[key] = librosa.power_to_db(\n",
    "            librosa.feature.melspectrogram(\n",
    "                to_mono(prediction),\n",
    "                sr=44100,\n",
    "                n_fft=2048,\n",
    "                hop_length=1024\n",
    "            ),\n",
    "            ref=np.max\n",
    "        )\n",
    "    spectrogram_slices.append(temp)\n",
    "\n",
    "# Prepare data for prediction\n",
    "x_test = []\n",
    "for spectrogram_slice in spectrogram_slices:\n",
    "    x_test.append(np.array(list(spectrogram_slice.values()))[:, : ,0:-1])\n",
    "\n",
    "print('Preprocessing finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Stem no original\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={'tf': tf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if model is loaded correctly\n",
    "# model.summary()\n",
    "# Predict\n",
    "for x in x_test:\n",
    "    model_prediction = model.predict(np.array([x]))\n",
    "    # Get most confident value\n",
    "    predictet_label = np.argmax(np.squeeze(model_prediction))\n",
    "    print(f'Model predictet {list(genres_dict.keys())[list(genres_dict.values()).index(predictet_label)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Simple game theory channel wise permutation interpretation\n",
    "l = [0,1]\n",
    "x_ = list(itertools.product(l, repeat=4))\n",
    "x_.remove((0,0,0,0))\n",
    "x_.remove((1,1,1,1))\n",
    "\n",
    "local_group = []\n",
    "for index, x in enumerate(x_test):\n",
    "    print(f'Slice number {index + 1}')\n",
    "    Z_y = []\n",
    "    \n",
    "    # Get prediction for full input\n",
    "    full_prediction = model.predict(np.array([x]))\n",
    "    full_predictet_confidence = np.amax(np.squeeze(full_prediction))\n",
    "    full_predictet_label = list(\n",
    "        genres_dict.keys())[\n",
    "        list(genres_dict\n",
    "             .values())\n",
    "        .index(\n",
    "            np.argmax(\n",
    "                np.squeeze(full_prediction)\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    print(f'Predicted {full_predictet_label} with confidence of {full_predictet_confidence}')\n",
    "    \n",
    "    # Create Sample and get label for prediction\n",
    "    for permutation in list(x_):\n",
    "        z = np.copy(x)\n",
    "        for index, value in enumerate(permutation):\n",
    "            if value == 0:\n",
    "                z[index] = np.full((z[index].shape[0], z[index].shape[1]), -80)\n",
    "        \n",
    "        model_prediction = model.predict(np.array([z]))\n",
    "        \n",
    "        # Get most confident value\n",
    "        predictet_label = np.argmax(np.squeeze(model_prediction))\n",
    "        Z_y.append(np.squeeze(model_prediction)[genres_dict[label]])\n",
    "        print(f'Model predictet {list(genres_dict.keys())[list(genres_dict.values()).index(predictet_label)]} for permutation {permutation}; Target label with {round(np.squeeze(model_prediction)[genres_dict[label]], 2)}')\n",
    "    \n",
    "    linear_reg_clf = LinearRegression()\n",
    "    linear_reg_clf.fit(x_, Z_y)\n",
    "    local_group.append(linear_reg_clf.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "channel = [\"vocals\", \"drums\", \"bass\", \"other\"]\n",
    "\n",
    "cmap = mpl.cm.viridis\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for index, line in enumerate(local_group):\n",
    "    ax.plot(channel, line, label=f'{time.strftime(\"%M:%S\", time.gmtime((index * 10)))} - {time.strftime(\"%M:%S\", time.gmtime((index + 1)* 10))}')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
